{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxbGjct7sdd0"
      },
      "source": [
        "# import required library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzFoQ1IOsdd4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N88IEHqrsdd5"
      },
      "source": [
        "# read dataset and do pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoXSsRFesdd6",
        "outputId": "61059f29-444a-48d0-b067-96edb4536eb6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1                                                 v2 Unnamed: 2  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "...    ...                                                ...        ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
              "5571   ham                         Rofl. Its true to its name        NaN   \n",
              "\n",
              "     Unnamed: 3 Unnamed: 4  \n",
              "0           NaN        NaN  \n",
              "1           NaN        NaN  \n",
              "2           NaN        NaN  \n",
              "3           NaN        NaN  \n",
              "4           NaN        NaN  \n",
              "...         ...        ...  \n",
              "5567        NaN        NaN  \n",
              "5568        NaN        NaN  \n",
              "5569        NaN        NaN  \n",
              "5570        NaN        NaN  \n",
              "5571        NaN        NaN  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jras3A0Ksdd7"
      },
      "outputs": [],
      "source": [
        "x = df[\"v2\"]\n",
        "y = df[\"v1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH_pnZ_Qsdd7",
        "outputId": "6d8e7df9-9e2a-4d4b-bd9c-b51ee168502a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       go until jurong point, crazy.. available only ...\n",
              "1                           ok lar... joking wif u oni...\n",
              "2       free entry in 2 a wkly comp to win fa cup fina...\n",
              "3       u dun say so early hor... u c already then say...\n",
              "4       nah i don't think he goes to usf, he lives aro...\n",
              "                              ...                        \n",
              "5567    this is the 2nd time we have tried 2 contact u...\n",
              "5568                will ì_ b going to esplanade fr home?\n",
              "5569    pity, * was in mood for that. so...any other s...\n",
              "5570    the guy did some bitching but i acted like i'd...\n",
              "5571                           rofl. its true to its name\n",
              "Name: v2, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# converting text to lower case\n",
        "x = x.apply(lambda x:x.lower())\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTfnglo1sdd7",
        "outputId": "736a528d-7be0-460a-f2e4-7c2703d1ae04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       go until jurong point crazy available only in ...\n",
              "1                                 ok lar joking wif u oni\n",
              "2       free entry in 2 a wkly comp to win fa cup fina...\n",
              "3             u dun say so early hor u c already then say\n",
              "4       nah i dont think he goes to usf he lives aroun...\n",
              "                              ...                        \n",
              "5567    this is the 2nd time we have tried 2 contact u...\n",
              "5568                  will ì b going to esplanade fr home\n",
              "5569    pity  was in mood for that soany other suggest...\n",
              "5570    the guy did some bitching but i acted like id ...\n",
              "5571                            rofl its true to its name\n",
              "Name: v2, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# removing punctuation\n",
        "def remove_punctuations(s):\n",
        "    punc_free_string = \"\".join([i for i in s if i not in string.punctuation])\n",
        "    return punc_free_string\n",
        "x = x.apply(remove_punctuations)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXAT3Lqksdd8",
        "outputId": "b6cfc0bb-c0fe-4823-fe34-f2ea9a8fe3dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [go, until, jurong, point, crazy, available, o...\n",
              "1                          [ok, lar, joking, wif, u, oni]\n",
              "2       [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3       [u, dun, say, so, early, hor, u, c, already, t...\n",
              "4       [nah, i, dont, think, he, goes, to, usf, he, l...\n",
              "                              ...                        \n",
              "5567    [this, is, the, 2nd, time, we, have, tried, 2,...\n",
              "5568         [will, ì, b, going, to, esplanade, fr, home]\n",
              "5569    [pity, was, in, mood, for, that, soany, other,...\n",
              "5570    [the, guy, did, some, bitching, but, i, acted,...\n",
              "5571                     [rofl, its, true, to, its, name]\n",
              "Name: v2, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenize the words\n",
        "x = x.apply(nltk.tokenize.word_tokenize)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBBX8bCvsdd8",
        "outputId": "3bd198bd-6bef-4c73-ab29-2967b04e4410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [go, jurong, point, crazy, available, bugis, n...\n",
              "1                          [ok, lar, joking, wif, u, oni]\n",
              "2       [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
              "3           [u, dun, say, early, hor, u, c, already, say]\n",
              "4       [nah, dont, think, goes, usf, lives, around, t...\n",
              "                              ...                        \n",
              "5567    [2nd, time, tried, 2, contact, u, u, å£750, po...\n",
              "5568                   [ì, b, going, esplanade, fr, home]\n",
              "5569                     [pity, mood, soany, suggestions]\n",
              "5570    [guy, bitching, acted, like, id, interested, b...\n",
              "5571                                   [rofl, true, name]\n",
              "Name: v2, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stop word removal\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "def remove_stopwords(ls):\n",
        "    return [i for i in ls if i not in stopwords]\n",
        "x = x.apply(remove_stopwords)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5nNtcevsdd9",
        "outputId": "720212d9-27cf-447b-b3d7-e410259c5d24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [go, jurong, point, crazy, available, bugis, n...\n",
              "1                          [ok, lar, joking, wif, u, oni]\n",
              "2       [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
              "3           [u, dun, say, early, hor, u, c, already, say]\n",
              "4       [nah, dont, think, go, usf, life, around, though]\n",
              "                              ...                        \n",
              "5567    [2nd, time, tried, 2, contact, u, u, å£750, po...\n",
              "5568                   [ì, b, going, esplanade, fr, home]\n",
              "5569                      [pity, mood, soany, suggestion]\n",
              "5570    [guy, bitching, acted, like, id, interested, b...\n",
              "5571                                   [rofl, true, name]\n",
              "Name: v2, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize(ls):\n",
        "    return [lemmatizer.lemmatize(i) for i in ls]\n",
        "x = x.apply(lemmatize)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H64AjS-esdd9"
      },
      "outputs": [],
      "source": [
        "# converting to bag of words\n",
        "x = x.apply(lambda i: \" \".join(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HFIzlppsdd9"
      },
      "outputs": [],
      "source": [
        "y = y.apply(lambda i: 1 if i == \"spam\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msSwew6Dsdd9"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpXaRQXgsdd-",
        "outputId": "482192ec-f7b3-44f2-cb8c-2cfc4dc8035d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4179,)"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTYgKORnsdd-"
      },
      "outputs": [],
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tokenizer = Tokenizer(max_words)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "sequences_mat = pad_sequences(sequences, maxlen = max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U47G9TgZsdd-"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13TmZov5sdd-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PohNsKYxsdd-"
      },
      "source": [
        "# Add Layers (LSTM, Dense-(Hidden Layers), Output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iXLHIU1sdd-"
      },
      "outputs": [],
      "source": [
        "model.add(Embedding(max_words, 50, input_length=max_len))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation=tf.keras.activations.sigmoid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk6RWXSosdd_"
      },
      "source": [
        "# compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBcuCLc4sdd_"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXPE28sysdd_"
      },
      "source": [
        "# fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeM44yKtsdd_",
        "outputId": "aab68560-52ef-4efd-c494-b26703952739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131/131 [==============================] - 51s 348ms/step - loss: 0.4200 - accuracy: 0.8579\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1595a44cf10>"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(sequences_mat, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ofZe1_dsdeA"
      },
      "source": [
        "# saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhmQvjKasdeA"
      },
      "outputs": [],
      "source": [
        "model.save(\"lstm_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4JQHGPsdeA"
      },
      "source": [
        "# test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYWicpgEsdeA",
        "outputId": "4b5c869c-0fe9-4081-beb5-1d24908a69df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ..., 719, 281,  10],\n",
              "       [  0,   0,   0, ...,  96, 273, 136],\n",
              "       [  0,   0,   0, ...,   0,  33,  96],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 826,  34,   1],\n",
              "       [  0,   0,   0, ...,   0, 211, 291],\n",
              "       [  0,   0,   0, ...,   0,  56,  18]])"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)\n",
        "test_sequences_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNLuJRkksdeA",
        "outputId": "f430ceeb-6120-4aea-cbd8-86b9d9fe2ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 10s 196ms/step - loss: 0.3574 - accuracy: 0.8744\n",
            "Accuracy: 0.8743718862533569\n",
            "Loss: 0.3573870062828064\n"
          ]
        }
      ],
      "source": [
        "accr = model.evaluate(test_sequences_matrix,y_test)\n",
        "print('Accuracy:',accr[1])\n",
        "print('Loss:',accr[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}